{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import pandas\n",
    "import pandas as pd\n",
    "# import urllib to deal with url connection\n",
    "from urllib.request import Request, urlopen\n",
    "# import beautiful soup to extract information from a webpage\n",
    "from bs4 import BeautifulSoup as bs\n",
    "# import regular expression lib\n",
    "import re\n",
    "# import multiprocessing lib to accelerate fetching data, windows does not support this lib\n",
    "from multiprocessing import Pool\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read birds list into a dataframe\n",
    "birds_list = pd.read_csv(\"birds_list.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Common name</th>\n",
       "      <th>Binomial</th>\n",
       "      <th>Category</th>\n",
       "      <th>Order</th>\n",
       "      <th>Family</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Southern cassowary</td>\n",
       "      <td>Casuarius casuarius</td>\n",
       "      <td>Cassowaries</td>\n",
       "      <td>Casuariformes</td>\n",
       "      <td>Casuariidae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Emu</td>\n",
       "      <td>Dromaius novaehollandiae</td>\n",
       "      <td>Emus</td>\n",
       "      <td>Casuariformes</td>\n",
       "      <td>Dromaiidae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>King Island emu</td>\n",
       "      <td>Dromaius ater</td>\n",
       "      <td>Emus</td>\n",
       "      <td>Casuariformes</td>\n",
       "      <td>Dromaiidae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Kangaroo Island emu</td>\n",
       "      <td>Dromaius baudinianus</td>\n",
       "      <td>Emus</td>\n",
       "      <td>Casuariformes</td>\n",
       "      <td>Dromaiidae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Australian brushturkey</td>\n",
       "      <td>Alectura lathami</td>\n",
       "      <td>Mound-builders</td>\n",
       "      <td>Galliformes</td>\n",
       "      <td>Megapodidae</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0             Common name                  Binomial  \\\n",
       "0           0      Southern cassowary       Casuarius casuarius   \n",
       "1           1                     Emu  Dromaius novaehollandiae   \n",
       "2           2         King Island emu             Dromaius ater   \n",
       "3           3     Kangaroo Island emu      Dromaius baudinianus   \n",
       "4           4  Australian brushturkey          Alectura lathami   \n",
       "\n",
       "         Category          Order       Family  \n",
       "0     Cassowaries  Casuariformes  Casuariidae  \n",
       "1            Emus  Casuariformes   Dromaiidae  \n",
       "2            Emus  Casuariformes   Dromaiidae  \n",
       "3            Emus  Casuariformes   Dromaiidae  \n",
       "4  Mound-builders    Galliformes  Megapodidae  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the head of the birds list\n",
    "birds_list.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the format of common name into lowercase with underscore, like 'australian_brushturkey'\n",
    "birds_list['Common_name_lowercase'] = birds_list['Common name'].str.lower()\n",
    "birds_list['Common_name_lowercase'] = birds_list['Common_name_lowercase'].str.replace(' ', '-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gerenate all the links to http://www.oiseaux-birds.com/ for every bird\n",
    "link_prefix = 'http://www.oiseaux-birds.com/'\n",
    "birds_list['link'] = link_prefix + 'card-' + birds_list['Common_name_lowercase'] + '.html'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# if one bird cannot found in http://www.oiseaux-birds.com/, then there will be a error page which length is 2282.\n",
    "ERROR_PAGE_LEN = 2282"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# try to get information for one specific bird\n",
    "\n",
    "url = \"http://www.oiseaux-birds.com/card-antipodean-albatross.html\"\n",
    "# use Firefox as an user-agent, otherwise the connection will be rejected.\n",
    "req = Request(url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "# get the content of a webpage\n",
    "webpage = urlopen(req).read()\n",
    "# convert to string\n",
    "webpage_str = str(webpage)\n",
    "# initialize a beautiful soup with lxml engine\n",
    "soup = bs(webpage, \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use regular expression to get height, it it doesn't exist, leave it blank.\n",
    "height = re.search('Height:(.*?)<br />', webpage_str)\n",
    "if height:\n",
    "    height = height.group(1).strip()\n",
    "else:\n",
    "    height = pd.np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use regular expression to get length, it it doesn't exist, leave it blank.\n",
    "length = re.search('Length:(.*?)<br />', webpage_str)\n",
    "if length:\n",
    "    length = length.group(1).strip()\n",
    "else:\n",
    "    length = pd.np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use regular expression to get weight, it it doesn't exist, leave it blank.\n",
    "weight = re.search('Weight:(.*?)</p>', webpage_str)\n",
    "if weight:\n",
    "    weight = weight.group(1).strip()\n",
    "else:\n",
    "    weight = pd.np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# find all img tags in html file\n",
    "imgs = soup.find_all(\"img\")\n",
    "if imgs:\n",
    "    # list comprehension to have a list of complete link of img files\n",
    "    imgs = [link_prefix + img['src'] for img in imgs]\n",
    "else:\n",
    "    imgs = pd.np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# find the position of voice link by regular expression\n",
    "voice = re.search('VOICE(.*?)</a>', webpage_str)\n",
    "if voice:\n",
    "    voice = voice.group(1).strip()\n",
    "    voice = re.search('<a href=\"(.*?)\"', voice)\n",
    "    if voice:\n",
    "        voice = voice.group(1).strip()\n",
    "        \n",
    "        # The parent of parent of parent of a tag contains 'VOICE' is where the voice link is\n",
    "        for elem in soup(text=re.compile(r'VOICE')):\n",
    "            voice_text = elem.parent.parent.parent.get_text()\n",
    "            voice_text = voice_text[6:].strip()\n",
    "            #print(voice_text)\n",
    "            #print(voice)\n",
    "else:\n",
    "    voice = pd.np.nan\n",
    "    voice_text = pd.np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Antipodean  Albatross is a pelagic seabird that comes to land only for breeding on  windswept subantarctic islands. The nest is often built among dense vegetation  such as tussock grass and shrubs. It usually avoids areas with tall vegetation,  and exposed tops of hills or ridges. \n",
      "    It forages  over the shelf edge and deep water where it can find abundant food.\n"
     ]
    }
   ],
   "source": [
    "# extract habitat by beautiful soup, if can not found, leave it blank\n",
    "habitat = re.search('HABITAT', webpage_str)\n",
    "if habitat:\n",
    "    for elem in soup(text=re.compile(r'HABITAT')):\n",
    "        habitat = elem.parent.parent.parent.get_text()\n",
    "        habitat = habitat[8:].strip()\n",
    "        print(habitat)\n",
    "else:\n",
    "    habitat = pd.np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Biometrics:  \n",
      "    Length:  110-117 cm\n",
      "    Wingspan:  280-330 cm\n",
      "    Weight:  M: 7240 g – F: 5790 g\n",
      "    Race “gibsoni”: M: 5500-8600 g – F: 4600-7300  g    \n",
      "The Antipodean  Albatross adult male of nominate race has mostly white body with variable, but  usually dense, dark brown vermiculations. The upperwing is almost plain dark  brown with whitish shafts on outer primaries. The black uppertail is tipped  white. \n",
      "    The underwing  is white with narrow trailing edge. \n",
      "    The head  is white, including forehead, chin and throat. The crown is often dark brown. There  is a variable amount of brownish blotching on the side of the rear part of head  and neck. \n",
      "    The bill  is pale pink, with the hooked tip of the upper mandible tinged yellowish to  horn. The eyes are dark brown. Legs and webbed feet are greyish to pink.\n"
     ]
    }
   ],
   "source": [
    "# extract description by beautiful soup, if can not found, leave it blank\n",
    "description = re.search('DESCRIPTION OF THE BIRD', webpage_str)\n",
    "if description:\n",
    "    for elem in soup(text=re.compile(r'DESCRIPTION OF THE BIRD')):\n",
    "        description = elem.parent.parent.parent.parent.get_text()\n",
    "        description = description[25:].strip()\n",
    "        print(description)\n",
    "else:\n",
    "    description = re.search('DESCRIPTION', webpage_str)\n",
    "    if description:\n",
    "        for elem in soup(text=re.compile(r'DESCRIPTION')):\n",
    "            description = elem.parent.parent.parent.get_text()\n",
    "            description = description[12:].strip()\n",
    "            print(description)\n",
    "    else:\n",
    "        description = pd.np.nan\n",
    "\n",
    "if description == description:\n",
    "    find_biometrics = re.search('Biometrics((?!to).|\\n)*\\d *(k?gr? *(\\(.*\\))?|cm *(\\(.*\\))?)\\.?', description)\n",
    "    if find_biometrics:\n",
    "        description = description[:find_biometrics.span()[0]] + description[find_biometrics.span()[1]:]\n",
    "        description = description.strip()\n",
    "    if len(description) > 0 and description[0] not in string.ascii_letters:\n",
    "        description = description[1:]\n",
    "    description = description.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract movements by beautiful soup, if can not found, leave it blank\n",
    "movements = re.search('MOVEMENTS', webpage_str)\n",
    "if movements:\n",
    "    for elem in soup(text=re.compile(r'MOVEMENTS')):\n",
    "        movements = elem.parent.parent.parent.get_text()\n",
    "        movements = movements[10:].strip()\n",
    "        print(movements)\n",
    "else:\n",
    "    movements = pd.np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OF THIS SPECIES: \n",
      "    The Antipodean  Albatross usually breeds biennially if successful. The laying occurs around January  on Antipodes Islands and around February on Chatham Islands. \n",
      "    The race  “gibsoni” breeds mostly in late December  on the Auckland Islands. \n",
      "    The nest  is a low truncated cone made with soil, twigs and roots, and the shallow  depression at top is sometimes lined with grass. It is often placed in open or  in scattered tussock grass or shrubs, and from coastline to inland areas such  as slopes or plateau.\n"
     ]
    }
   ],
   "source": [
    "# extract reproduction by beautiful soup, if can not found, leave it blank\n",
    "reproduction = re.search('REPRODUCTION', webpage_str)\n",
    "if reproduction:\n",
    "    for elem in soup(text=re.compile(r'REPRODUCTION')):\n",
    "        reproduction = elem.parent.parent.parent.get_text()\n",
    "        reproduction = reproduction[13:].strip()\n",
    "        print(reproduction)\n",
    "else:\n",
    "    reproduction = pd.np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract diet by beautiful soup, if can not found, leave it blank\n",
    "diet = re.search('DIET', webpage_str)\n",
    "if diet:\n",
    "    for elem in soup(text=re.compile(r'DIET')):\n",
    "        diet = elem.parent.parent.parent.get_text()\n",
    "        diet = diet[5:].strip()\n",
    "        print(diet)\n",
    "else:\n",
    "    diet = pd.np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Antipodean  Albatross is affected by introduced predators such as pigs, cats, rats and mice  on some breeding islands. However, the main threat is at sea where the birds  take bait from hooks. Numerous birds are killed by long-line fisheries,  involving important declines over several following years. The global warming  also changes the ocean conditions and reduces prey abundance.\n",
      "    In 2009,  the global population was estimated to number 44,500 mature individuals. There were  4,565 breeding pairs on Antipodes Islands in 2007/2009, and 3,277 pairs in the  Auckland group between 2006 and 2009. \n",
      "    The Antipodean  Albatross has reduced breeding range on some subantarctic islands. It is currently  classified as Vulnerable, but following declines, it could be reclassified as  Endangered or even Critically Endangered.\n"
     ]
    }
   ],
   "source": [
    "# extract protection by beautiful soup, if can not found, leave it blank\n",
    "protection = re.search('PROTECTION', webpage_str)\n",
    "if protection:\n",
    "    for elem in soup(text=re.compile(r'PROTECTION')):\n",
    "        protection = elem.parent.parent.parent.get_text()\n",
    "        protection = protection[31:].strip()\n",
    "        print(protection)\n",
    "else:\n",
    "    protection = pd.np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HANDBOOK  OF THE BIRDS OF THE WORLD vol 1 by Josep del Hoyo-Andrew Elliot-Jordi Sargatal - Lynx Edicions - ISBN:  8487334105  \n",
      "A  Complete Guide to Antarctic Wildlife by Hadoram Shirihai and Illustrated by Brett  Jarrett - Edited by Guy M. Kirwan - ALUL.A Press Oy, Finland - ISBN 9519894705\n",
      "Avibase (Denis Lepage) \n",
      "BirdLife International \n",
      "HBW Alive \n",
      "ARKive (Christopher Parsons)  \n",
      "New Zealand Birds Online  \n",
      "Report  prepared for Department of Conservation by Graeme Elliott and Kath Walker -  November 2014\n",
      "Antipodean wandering albatross –  population study \n",
      "NSW Government – Office of Environment  & Heritage  \n",
      "Birds in Danger – Australia’s  Threatened Birds  \n",
      "New Zealand bird status between 2008  and 2012 \n",
      "Department of Sustainability,  Environment, Water, Population and Communities \n",
      "Ocean  Wanderers \"Ride the Wave\"\n"
     ]
    }
   ],
   "source": [
    "# extract sources by beautiful soup, if can not found, leave it blank\n",
    "sources = re.search('Sources', webpage_str)\n",
    "if sources:\n",
    "    for elem in soup(text=re.compile(r'Sources')):\n",
    "        sources = elem.parent.parent.parent.parent.get_text()\n",
    "        sources = sources[sources.find(\"Sources\") + 9:sources.find(\"Home page\")].strip()\n",
    "        print(sources)\n",
    "else:\n",
    "    sources = pd.np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a error_list, if one bird can not find in this website, then add it into this list\n",
    "error_list = []\n",
    "\n",
    "# define a fetch function to get all the information for a multiprocessing pool\n",
    "def fetch(idx):\n",
    "    url = birds_list.ix[idx, 'link']\n",
    "    req = Request(url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "    webpage = urlopen(req).read()\n",
    "    webpage_str = str(webpage)\n",
    "    soup = bs(webpage, \"lxml\")\n",
    "    imgs_dict = dict()\n",
    "    \n",
    "    if len(webpage) == ERROR_PAGE_LEN:\n",
    "        error_list.append(idx)\n",
    "        return pd.np.nan\n",
    "    \n",
    "    height = re.search('Height:(.*?)<br />', webpage_str)\n",
    "    if height:\n",
    "        height = height.group(1).strip()\n",
    "    else:\n",
    "        height = pd.np.nan\n",
    "    \n",
    "    length = re.search('Length:(.*?)<br />', webpage_str)\n",
    "    if length:\n",
    "        length = length.group(1).strip()\n",
    "    else:\n",
    "        length = pd.np.nan\n",
    "\n",
    "    weight = re.search('Weight:(.*?)</p>', webpage_str)\n",
    "    if weight:\n",
    "        weight = weight.group(1).strip()\n",
    "    else:\n",
    "        weight = pd.np.nan\n",
    "    \n",
    "    imgs = soup.find_all(\"img\")\n",
    "    if imgs:\n",
    "        imgs = [link_prefix + img['src'] for img in imgs]\n",
    "    else:\n",
    "        imgs = pd.np.nan\n",
    "    \n",
    "    voice = re.search('VOICE(.*?)</a>', webpage_str)\n",
    "    if voice:\n",
    "        voice = voice.group(1).strip()\n",
    "        voice = re.search('<a href=\"(.*?)\"', voice)\n",
    "        if voice:\n",
    "            voice = voice.group(1).strip()\n",
    "\n",
    "            for elem in soup(text=re.compile(r'VOICE')):\n",
    "                voice_text = elem.parent.parent.parent.get_text()\n",
    "                voice_text = voice_text[6:].strip()\n",
    "                #print(voice_text)\n",
    "                #print(voice)\n",
    "    else:\n",
    "        voice = pd.np.nan\n",
    "        voice_text = pd.np.nan\n",
    "    \n",
    "    habitat = re.search('HABITAT', webpage_str)\n",
    "    if habitat:\n",
    "        for elem in soup(text=re.compile(r'HABITAT')):\n",
    "            habitat = elem.parent.parent.parent.get_text()\n",
    "            habitat = habitat[8:].strip()\n",
    "            #print(habitat)\n",
    "    else:\n",
    "        habitat = pd.np.nan\n",
    "    \n",
    "    description = re.search('DESCRIPTION OF THE BIRD', webpage_str)\n",
    "    if description:\n",
    "        for elem in soup(text=re.compile(r'DESCRIPTION OF THE BIRD')):\n",
    "            description = elem.parent.parent.parent.parent.get_text()\n",
    "            description = description[25:].strip()\n",
    "            # print(description)\n",
    "    else:\n",
    "        description = re.search('DESCRIPTION', webpage_str)\n",
    "        if description:\n",
    "            for elem in soup(text=re.compile(r'DESCRIPTION')):\n",
    "                description = elem.parent.parent.parent.get_text()\n",
    "                description = description[12:].strip()\n",
    "                # print(description)\n",
    "        else:\n",
    "            description = pd.np.nan\n",
    "    if description == description:\n",
    "        find_biometrics = re.search('Biometrics((?!to).|\\n)*\\d *(k?gr? *(\\(.*\\))?|cm *(\\(.*\\))?)\\.?', description)\n",
    "        if find_biometrics:\n",
    "            description = description[:find_biometrics.span()[0]] + description[find_biometrics.span()[1]:]\n",
    "            description = description.strip()\n",
    "        if len(description) > 0 and description[0] not in string.ascii_letters:\n",
    "            description = description[1:]\n",
    "        description = description.strip()\n",
    "    \n",
    "    movements = re.search('MOVEMENTS', webpage_str)\n",
    "    if movements:\n",
    "        for elem in soup(text=re.compile(r'MOVEMENTS')):\n",
    "            movements = elem.parent.parent.parent.get_text()\n",
    "            movements = movements[10:].strip()\n",
    "            #print(movements)\n",
    "    else:\n",
    "        movements = pd.np.nan\n",
    "    \n",
    "    reproduction = re.search('REPRODUCTION', webpage_str)\n",
    "    if reproduction:\n",
    "        for elem in soup(text=re.compile(r'REPRODUCTION')):\n",
    "            reproduction = elem.parent.parent.parent.get_text()\n",
    "            reproduction = reproduction[13:].strip()\n",
    "            #print(reproduction)\n",
    "    else:\n",
    "        reproduction = pd.np.nan\n",
    "    \n",
    "    diet = re.search('DIET', webpage_str)\n",
    "    if diet:\n",
    "        for elem in soup(text=re.compile(r'DIET')):\n",
    "            diet = elem.parent.parent.parent.get_text()\n",
    "            diet = diet[5:].strip()\n",
    "            #print(diet)\n",
    "    else:\n",
    "        diet = pd.np.nan\n",
    "    \n",
    "    protection = re.search('PROTECTION', webpage_str)\n",
    "    if protection:\n",
    "        for elem in soup(text=re.compile(r'PROTECTION')):\n",
    "            protection = elem.parent.parent.parent.get_text()\n",
    "            protection = protection[31:].strip()\n",
    "            #print(protection)\n",
    "    else:\n",
    "        protection = pd.np.nan\n",
    "    \n",
    "    sources = re.search('Sources', webpage_str)\n",
    "    if sources:\n",
    "        for elem in soup(text=re.compile(r'Sources')):\n",
    "            sources = elem.parent.parent.parent.parent.get_text()\n",
    "            sources = sources[sources.find(\"Sources\") + 9:sources.find(\"Home page\")].strip()\n",
    "            #print(sources)\n",
    "    else:\n",
    "        sources = pd.np.nan\n",
    "    \n",
    "    birds_list.ix[idx, 'height'] = height\n",
    "    birds_list.ix[idx, 'length'] = length\n",
    "    birds_list.ix[idx, 'weight'] = weight\n",
    "    if imgs == imgs:\n",
    "        imgs_dict[idx] = imgs\n",
    "    birds_list.ix[idx, 'voice'] = voice\n",
    "    birds_list.ix[idx, 'habitat'] = habitat\n",
    "    birds_list.ix[idx, 'description'] = description\n",
    "    birds_list.ix[idx, 'movements'] = movements\n",
    "    birds_list.ix[idx, 'reproduction'] = reproduction\n",
    "    birds_list.ix[idx, 'diet'] = diet\n",
    "    birds_list.ix[idx, 'protection'] = protection\n",
    "    birds_list.ix[idx, 'sources'] = sources\n",
    "\n",
    "    imgs_dict[idx] = imgs\n",
    "    \n",
    "    return (birds_list.ix[idx], imgs_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Even with 20 process at one time, checking about 900 birds still takes very long time, seperate them into 5 parts, otherwise it may crash or get timeout when executing these tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new Pool object\n",
    "multi_pool = Pool(processes=20)\n",
    "# Extract all info\n",
    "new_bird_list = multi_pool.map(fetch, range(200))\n",
    "# Close Multiprocessing Pool\n",
    "multi_pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new Pool object\n",
    "multi_pool = Pool(processes=20)\n",
    "# Extract all info\n",
    "new_bird_list1 = multi_pool.map(fetch, range(200, 400))\n",
    "# Close Multiprocessing Pool\n",
    "multi_pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a new Pool object\n",
    "multi_pool = Pool(processes=20)\n",
    "# Extract all info\n",
    "new_bird_list2 = multi_pool.map(fetch, range(400, 600))\n",
    "# Close Multiprocessing Pool\n",
    "multi_pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a new Pool object\n",
    "multi_pool = Pool(processes=20)\n",
    "# Extract all info\n",
    "new_bird_list3 = multi_pool.map(fetch, range(600, 800))\n",
    "# Close Multiprocessing Pool\n",
    "multi_pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a new Pool object\n",
    "multi_pool = Pool(processes=20)\n",
    "# Extract all info\n",
    "new_bird_list4 = multi_pool.map(fetch, range(800, len(birds_list)))\n",
    "# Close Multiprocessing Pool\n",
    "multi_pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# combine all 5 parts data into one list\n",
    "birds_list_cleaned = new_bird_list + new_bird_list1 + new_bird_list2 + new_bird_list3 + new_bird_list4\n",
    "birds_list_cleaned = [bird for bird in birds_list_cleaned if type(bird) is not float]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check how many birds have got in oiseaux-birds\n",
    "len(birds_list_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_list = [bird[1] for bird in birds_list_cleaned]\n",
    "birds_list_cleaned = [bird[0] for bird in birds_list_cleaned]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Common name', 'Binomial', 'Category', 'Order', 'Family',\n",
       "       'Common_name_lowercase', 'link', 'height', 'length', 'weight', 'voice',\n",
       "       'habitat', 'description', 'movements', 'reproduction', 'diet',\n",
       "       'protection', 'sources'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a new dataframe with data from oiseaux-birds\n",
    "birds_new_df = pd.DataFrame(birds_list_cleaned)\n",
    "birds_new_df = birds_new_df.rename(columns={'Unnamed: 0': 'id'})\n",
    "birds_new_df.set_index('id', inplace=True)\n",
    "birds_new_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a img dataframe to store all img links for each birds\n",
    "imgs_dict = dict()\n",
    "for imgs in imgs_list:\n",
    "    imgs_dict.update(imgs)\n",
    "\n",
    "imgs_df = pd.DataFrame(dict([(k, pd.Series(v)) for k,v in imgs_dict.items()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save new dataframe to csv file\n",
    "birds_new_df.to_csv(\"birds.csv\")\n",
    "imgs_df.to_csv(\"imgs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new dataframe to store the birds cannot find in oiseaux and save it to a csv file\n",
    "incomplete_df = birds_list[~birds_list.index.isin(birds_new_df.index)]\n",
    "incomplete_df.to_csv(\"can_not_find_in_oiseaux.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
